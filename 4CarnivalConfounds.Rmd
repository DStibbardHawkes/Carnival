---
title: "Controlling for Experimental Confounds"
output: html_notebook
---


### Packages and Data ###

In this document we're going to look at the effect of three experimental artefacts, to see if they represent potential confounds. As ever, we'll start by loading our packages. 

(These analyses were conducted on the XXXth of XXX 202X. If any of the packages or functions used in this analysis are now broken or depreciated, consider using the groundhog package with this date to load packages.)

```{r}
##load packages (all on CRAN; use install.packages() if first time)
library(brms) #Bayesian regressions with STAN
library(tidyverse) #Load dplyr, ggplot and others
library(tidybayes) #Useful functions for describing posterior (e.g., mean_hdi)
library(ggplot2) #Good-looking visualization package
library(bayesplot) #Quick and easy coef plots.
library(ggridges) #Fancy density ridgeplots for fancy people.
library(magrittr) #For two-way pipes
library(rstudioapi) #Allows RStudio to get the current working directory.
library(patchwork) #Easily stitch figures together with operators.
library(xtable) # Brings many types table format to the table. Used here to export LaTeX tables.  
library(ggtext) #Use HTML Elements in GGPlot
``` 

Next let's load the data. As before, this uses the rstudio API and requires that the appropriate .rda file be in the same folder as this script.

```{r}
setwd(dirname(getActiveDocumentContext()$path))
load("carnivaldata.rda")
load("carnivalmodels.rda")
```

In case there are any sources of (psuedo-)random variation in our functions, let's set a RNG seed.

```{r}
set.seed(42)
```

Now we can start examining those potential confounds.

### Controlling for potential experimental confounds ###

## Game Order ##

The first potential experimental artefact is game order - whether people played the hunting or the gathering game first. This has the potential to confound our game-type difference.

```{r}

FgGt <- brm(data = d,
              family = bernoulli,
              Played1 ~ 0 + firstgame + Game_Type,
              prior = c(prior(normal(0, 1), class = b)),
              seed = 42,
              iter = 10000, warmup = 5000, chains = 1, cores = 1,
              #control = list(adapt_delta = .95),
              file = "fits/FgGt",
          )

FgGt <- add_criterion(FgGt, criterion = c("loo", "waic")) 


```

Let's briefly inspect our probability-scale estimates using the fitted function.

```{r}
nd <-  d %>% 
  distinct(firstgame, Game_Type)

FgGtFit <- fitted(FgGt, newdata = nd, probs = c(.05,.95)) %>% 
  data.frame() %>% 
  bind_cols(nd) %>%
  unite(col = "new", c(firstgame, Game_Type), sep = "_") %>%
  ggplot(aes(x = Estimate, y = new)) + geom_point() + geom_errorbar(aes(xmin = Q5, xmax = Q95),width=0, lwd = 1) + scale_y_discrete(labels= c("ForageGame_ForageFirst","HuntGame_ForageFirst", "ForageGame_HuntFirst", "HuntGame_HuntFirst"))

FgGtFit
```

As we can see, playing the hunting game first lead to an increase in probability of playing, independent of game type. Looking at the means, about 3% in absolute terms. However, the overlap between the hunt first and forage first distributions was substantial, so this could be a consequence of chance. Let's compare this model with the game type only model


```{r}


ms5 <- loo_compare(GameType, FgGt, criterion = "loo") %>%
  round(digits = 2) %>% 
  as.data.frame() %>% 
  select(elpd_diff,se_diff) %>% 
  rownames_to_column() %>%
  arrange(rowname)
  
ms5 <- model_weights(GameType, FgGt, weights = "loo") %>% 
  round(digits = 2) %>%
  as.data.frame() %>% 
  rownames_to_column() %>%
  arrange(rowname) %>%
  column_to_rownames("rowname") %>%
  cbind(ms5) %>%
  rename(
    Weights = ".",
    "ELPD Difference" = elpd_diff,
    "SE Difference" = "se_diff"
  ) %>%
  arrange(desc(`ELPD Difference`)) %>%
  select(-rowname)
  
ms5

```

As we can see, the model including first game is a represents a small improvement on the model including game type only, but the models are largely comparable. The first chosen game has a small but not substantial influence. Equivocal improvement in model fit, so probably safe to exclude from the text body.


## Prize Colour ##

The next question is does bracelet colour affect probability of playing. Since not all rounds had a prize, we're going to limit our selection here to those games which had bracelets.

```{r}

dbracelet <- d %>%
  filter(Prize != "NA")

```

...and we'll compare the bracelet only condition to the intercept only model.

```{r}


PrizeConditionBaseline <- brm(
  data = dbracelet, family = bernoulli,
  Played1 ~ 1,
  prior = c(prior(normal(0, 1), class = Intercept)),
  iter = 10000, warmup = 5000, cores = 4, chains = 4,
  #control = list(adapt_delta = .9),
  seed = 42,
  file = "fits/PrizeConditionBaseline"
)

PrizeConditionBaseline <- add_criterion(PrizeConditionBaseline, criterion = c("loo")) 

PrizeColor <- brm(data = dbracelet,
              family = bernoulli,
              Played1 ~ 0 + Prize,
              prior = c(prior(normal(0, 1), class = b)),
              seed = 42,
              iter = 10000, warmup = 5000, chains = 1, cores = 1,
              #control = list(adapt_delta = .95),
              file = "fits/PrizeColor",
          )

PrizeColor <- add_criterion(PrizeColor, criterion = c("loo")) 
```

Let's briefly inspect our estimates. Only a single response variable so just a quick mcmc plot this time will do.


```{r}
mcmc_plot(PrizeColor)
```

As we can see a mild preference for red bracelets but substantial overlap between distributions. Let's compare the model including prize colour to the baseline. 

```{r}
ms6 <- loo_compare(PrizeColor, PrizeConditionBaseline, criterion = "loo") %>%
  round(digits = 2) %>% 
  as.data.frame() %>% 
  select(elpd_diff,se_diff) %>% 
  rownames_to_column() %>%
  arrange(rowname)
  
ms6 <- model_weights(PrizeColor, PrizeConditionBaseline, weights = "loo") %>% 
  round(digits = 2) %>%
  as.data.frame() %>% 
  rownames_to_column() %>%
  arrange(rowname) %>%
  column_to_rownames("rowname") %>%
  cbind(ms6) %>%
  rename(
    Weights = ".",
    "ELPD Difference" = elpd_diff,
    "SE Difference" = "se_diff"
  ) %>%
  arrange(desc(`ELPD Difference`)) %>%
  select(-rowname)
  
ms6
```
Once again the results are equivocal, with some weight allotted to both models. Here the baseline is preferred. Again it appears safe to discount the impact of prize colour as substantially influencing choices. Let's explore the final potential methodological artifact, round number.

## Round Number ##

Our final Bernoulli trials assume that each event is independent. In fact ours are aren't, because with each subsequent round the chance to play decreases. This would not be greatly problematic if each condition had the same number of rounds. However, some conditions had more rounds than others - especially because we estimated our no pay, prize condition using a single free round. 

As round number should predominantly impact condition-level differences we'll start with a model that includes condition and round number.

```{r}

NCrGt <- brm(data = d,
              family = bernoulli,
              Played1 ~ 0 + Condition + Round_Number + (0 + Condition + Round_Number | Game_Type),
              prior = c(prior(normal(0, 1), class = b)
                        ,prior(exponential(1), class = sd, group = Game_Type)
                        ,prior(lkj(2), class = cor, group = Game_Type)),
              seed = 42,
              iter = 10000, warmup = 5000, chains = 4, cores = 4,
              control = list(adapt_delta = .999),
              #This many iterations banishes some error messages but takes a while to run. 
              #Consider adjusting if you're not using a fast CPU.
              file = "fits/NCrGt",
          )

NCrGt <- add_criterion(NCrGt, criterion = c("loo", "waic")) 

```

Lets see how this compares to the 'Condition | game_type' only model.

```{r}

ms7 <- loo_compare(NCrGt, CrGt, criterion = "loo") %>%
  round(digits = 2) %>% 
  as.data.frame() %>% 
  select(elpd_diff,se_diff) %>% 
  rownames_to_column() %>%
  arrange(rowname)
  
ms7 <- model_weights(NCrGt, CrGt, weights = "loo") %>% 
  round(digits = 2) %>%
  as.data.frame() %>% 
  rownames_to_column() %>%
  arrange(rowname) %>%
  column_to_rownames("rowname") %>%
  cbind(ms7) %>%
  rename(
    Weights = ".",
    "ELPD Difference" = elpd_diff,
    "SE Difference" = "se_diff"
  ) %>%
  arrange(desc(`ELPD Difference`)) %>%
  select(-rowname)
  
ms7
```

A substantial improvement. Adding round number makes a very large impact, and is worth investigating further. Let's add it to the 'full' model.

```{r}
NCrGtrSrA <- brm(data = d,
              family = bernoulli,
              Played1 ~ 0 + Round_Number + Condition + (0 + Round_Number + Condition | Game_Type) 
              + (0 + Round_Number + Condition | sex) + (0 + Round_Number + Condition | AgeSplit),
              prior = c(prior(normal(0, 1), class = b)
                        ,prior(exponential(1), class = sd, group = Game_Type)
                        ,prior(lkj(2), class = cor, group = Game_Type)
                        ,prior(exponential(1), class = sd, group = sex)
                        ,prior(lkj(2), class = cor, group = sex)
                        ,prior(exponential(1), class = sd, group = AgeSplit)
                        ,prior(lkj(2), class = cor, group = AgeSplit)
                        ),
              seed = 42,
              iter = 10000, warmup = 5000, chains = 6, cores = 6,
              control = list(adapt_delta = .999),
              #This settings banish some error messages but takes a while to run. 
              #Consider adjusting if you're not using a fast CPU.
              file = "fits/NCrGtrSrA",
          )

NCrGtrSrA <- add_criterion(NCrGtrSrA, criterion = c("loo", "waic"))
```

Now let's see if adding round number improves upon the full model.

```{r}

ms8 <- loo_compare(CrGtrSrA, NCrGtrSrA, criterion = "loo") %>%
  round(digits = 2) %>% 
  as.data.frame() %>% 
  select(elpd_diff,se_diff) %>% 
  rownames_to_column() %>%
  arrange(rowname)
  
ms8 <- model_weights(CrGtrSrA, NCrGtrSrA, weights = "loo") %>% 
  round(digits = 2) %>%
  as.data.frame() %>% 
  rownames_to_column() %>%
  arrange(rowname) %>%
  column_to_rownames("rowname") %>%
  cbind(ms8) %>%
  rename(
    Weights = ".",
    "ELPD Difference" = elpd_diff,
    "SE Difference" = "se_diff"
  ) %>%
  arrange(desc(`ELPD Difference`)) %>%
  select(-rowname)
  
ms8

```

Substantially, as it transpires. Since round number is continuous, the complete model will be tricky to visualize. I'm going to use what McElreath charmingly calls a triptych, showing fitted predictions for round numbers 1, 3 (the mean value) and 5. 

There are probably more efficient ways of coding this. But this will do.

```{r}

nd <-  d %>% 
  distinct(AgeSplit, Condition, Game_Type, sex) %>%
  mutate(Round_Number = 1)

NewLabs <- c("P0B1F","P0B1H", "P0B0F", "P0B0H", "P1B1F","P1B1H", "P1B0F", "P1B0H")

NCrGtrSrAFitM1 <- fitted(NCrGtrSrA, newdata = nd, probs = c(.05,.95)) %>% 
  data.frame() %>% 
  bind_cols(nd) %>%
  filter(sex == "M") %>%
  unite(col = "new", c(Condition, Game_Type, sex), sep = "_") %>%
  ggplot(aes(x = Estimate, y = new, color = AgeSplit)) + geom_point( position = position_dodge(.9)) + 
  geom_errorbar(aes(xmin = Q5, xmax = Q95),width=0, lwd = 1,  position = position_dodge(.9))+
  theme(legend.position = "none", axis.title = element_blank()) + scale_y_discrete(labels= NewLabs)

NCrGtrSrAFitF1 <- fitted(NCrGtrSrA, newdata = nd, probs = c(.05,.95)) %>% 
  data.frame() %>% 
  bind_cols(nd) %>%
  filter(sex == "F") %>%
  unite(col = "new", c(Condition, Game_Type, sex), sep = "_") %>%
  ggplot(aes(x = Estimate, y = new, color = AgeSplit)) + geom_point( position = position_dodge(.9)) + 
  geom_errorbar(aes(xmin = Q5, xmax = Q95),width=0, lwd = 1,  position = position_dodge(.9))  + 
  theme(axis.title = element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank(), legend.position = "none")

nd <-  d %>% 
  distinct(AgeSplit, Condition, Game_Type, sex) %>%
  mutate(Round_Number = 3)

NCrGtrSrAFitM3 <- fitted(NCrGtrSrA, newdata = nd, probs = c(.05,.95)) %>% 
  data.frame() %>% 
  bind_cols(nd) %>%
  filter(sex == "M") %>%
  unite(col = "new", c(Condition, Game_Type, sex), sep = "_") %>%
  ggplot(aes(x = Estimate, y = new, color = AgeSplit)) + geom_point( position = position_dodge(.9)) + 
  geom_errorbar(aes(xmin = Q5, xmax = Q95),width=0, lwd = 1,  position = position_dodge(.9)) +
  theme(legend.position = "none", axis.title = element_blank()) + scale_y_discrete(labels= NewLabs)


NCrGtrSrAFitF3 <- fitted(NCrGtrSrA, newdata = nd, probs = c(.05,.95)) %>% 
  data.frame() %>% 
  bind_cols(nd) %>%
  filter(sex == "F") %>%
  unite(col = "new", c(Condition, Game_Type, sex), sep = "_") %>%
  ggplot(aes(x = Estimate, y = new, color = AgeSplit)) + geom_point( position = position_dodge(.9)) + 
  geom_errorbar(aes(xmin = Q5, xmax = Q95),width=0, lwd = 1,  position = position_dodge(.9)) + 
  theme(axis.title = element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank())

nd <-  d %>% 
  distinct(AgeSplit, Condition, Game_Type, sex) %>%
  mutate(Round_Number = 5)

NCrGtrSrAFitM5 <- fitted(NCrGtrSrA, newdata = nd, probs = c(.05,.95)) %>% 
  data.frame() %>% 
  bind_cols(nd) %>%
  filter(sex == "M") %>%
  unite(col = "new", c(Condition, Game_Type, sex), sep = "_") %>%
  ggplot(aes(x = Estimate, y = new, color = AgeSplit)) + geom_point( position = position_dodge(.9)) + 
  geom_errorbar(aes(xmin = Q5, xmax = Q95),width=0, lwd = 1,  position = position_dodge(.9)) +
  theme(legend.position = "none",axis.title.y = element_blank()) + scale_y_discrete(labels= NewLabs)

NCrGtrSrAFitF5 <- fitted(NCrGtrSrA, newdata = nd, probs = c(.05,.95)) %>% 
  data.frame() %>% 
  bind_cols(nd) %>%
  filter(sex == "F") %>%
  unite(col = "new", c(Condition, Game_Type, sex), sep = "_") %>%
  ggplot(aes(x = Estimate, y = new, color = AgeSplit)) + geom_point( position = position_dodge(.9)) + 
  geom_errorbar(aes(xmin = Q5, xmax = Q95),width=0, lwd = 1,  position = position_dodge(.9)) + 
  theme(axis.title = element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank(), legend.position = "none")


NCrGtrSrAFitM1 + NCrGtrSrAFitF1 +
NCrGtrSrAFitM3 + NCrGtrSrAFitF3 +
NCrGtrSrAFitM5 + NCrGtrSrAFitF5 + 
plot_layout(ncol = 2, nrow = 3)

```

This is a complex model, but the outputs make sense. Here we've put women on the right column, men on the left column, and the rows (top to bottom) represent fitted estimates for rounds 1 (min), 3 (median), and 5 (max). 

All of our contrasts of interest show a similar pattern to the model which did not include round number. Mean estimates are still typically higher for men than for women. Younger people of both genders are more likely to play than older people. The free rounds are all more popular than the pay rounds. The hunting game is more popular than the gathering game. But for the two pay conditions for men, the prize conditions are more popular than the no prize conditions. Unsurprisingly, the fitted estimated when round number is at its average value (i.e., round three) is very similar to the model which excluded round number. The only notable difference is some shrinkage for the free/prize rounds (to be expected as we only have round 1 data for these).

Modelling round number tells us two things. First, as expected, the probability of playing drops with each passing round. Second, the uncertainty over the pay 0, prize 1 condition (for which we only have round 1 data) decreases with each round, while the certainty for the pay conditions (which were never round 1) increases. 

Since the predictions are rather similar to those of the full model, it make s more sense to report the full model in the manuscript itself. 

Let's finish by printing out our session info.

```{r}
sessionInfo()
```

